{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG PIPELINE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beyondllm in c:\\python312\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: youtube_transcript_api in c:\\python312\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: llama-index-readers-youtube-transcript in c:\\python312\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: llama_index.embeddings.huggingface in c:\\python312\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: llama-index==0.10.27 in c:\\python312\\lib\\site-packages (from beyondllm) (0.10.27)\n",
      "Requirement already satisfied: llama-index-embeddings-gemini==0.1.6 in c:\\python312\\lib\\site-packages (from beyondllm) (0.1.6)\n",
      "Requirement already satisfied: nltk==3.8.1 in c:\\python312\\lib\\site-packages (from beyondllm) (3.8.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\python312\\lib\\site-packages (from beyondllm) (1.26.4)\n",
      "Requirement already satisfied: openai==1.20.0 in c:\\python312\\lib\\site-packages (from beyondllm) (1.20.0)\n",
      "Requirement already satisfied: pandas==2.0.3 in c:\\python312\\lib\\site-packages (from beyondllm) (2.0.3)\n",
      "Requirement already satisfied: pydantic<2,>=1.10.5 in c:\\python312\\lib\\site-packages (from beyondllm) (1.10.17)\n",
      "Requirement already satisfied: pypdf==4.2.0 in c:\\python312\\lib\\site-packages (from beyondllm) (4.2.0)\n",
      "Requirement already satisfied: pysbd==0.3.4 in c:\\python312\\lib\\site-packages (from beyondllm) (0.3.4)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in c:\\python312\\lib\\site-packages (from beyondllm) (6.0.1)\n",
      "Requirement already satisfied: regex==2024.4.16 in c:\\python312\\lib\\site-packages (from beyondllm) (2024.4.16)\n",
      "Requirement already satisfied: sqlalchemy==2.0.29 in c:\\python312\\lib\\site-packages (from beyondllm) (2.0.29)\n",
      "Requirement already satisfied: tiktoken==0.6.0 in c:\\python312\\lib\\site-packages (from beyondllm) (0.6.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.2.7)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.27 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.10.66)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.10)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.6)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.25)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.7)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.6)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.27)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\python312\\lib\\site-packages (from llama-index==0.10.27->beyondllm) (0.1.6)\n",
      "Requirement already satisfied: google-generativeai<0.5.0,>=0.4.1 in c:\\python312\\lib\\site-packages (from llama-index-embeddings-gemini==0.1.6->beyondllm) (0.4.1)\n",
      "Requirement already satisfied: click in c:\\python312\\lib\\site-packages (from nltk==3.8.1->beyondllm) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk==3.8.1->beyondllm) (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from nltk==3.8.1->beyondllm) (4.66.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai==1.20.0->beyondllm) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai==1.20.0->beyondllm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai==1.20.0->beyondllm) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai==1.20.0->beyondllm) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai==1.20.0->beyondllm) (4.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas==2.0.3->beyondllm) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas==2.0.3->beyondllm) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python312\\lib\\site-packages (from pandas==2.0.3->beyondllm) (2024.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python312\\lib\\site-packages (from sqlalchemy==2.0.29->beyondllm) (3.0.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\python312\\lib\\site-packages (from tiktoken==0.6.0->beyondllm) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\python312\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (0.23.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in c:\\python312\\lib\\site-packages (from llama_index.embeddings.huggingface) (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (24.0)\n",
      "Requirement already satisfied: aiohttp in c:\\python312\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (3.9.5)\n",
      "Requirement already satisfied: minijinja>=1.0 in c:\\python312\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (2.0.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (1.0.8)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\okan_\\appdata\\roaming\\python\\python312\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (3.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (10.3.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (8.3.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\python312\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.6.0->beyondllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.6.0->beyondllm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.6.0->beyondllm) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.6.0->beyondllm) (2024.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\python312\\lib\\site-packages (from sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (4.42.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\python312\\lib\\site-packages (from sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\python312\\lib\\site-packages (from sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\python312\\lib\\site-packages (from sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (1.13.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python312\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python312\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python312\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python312\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index.embeddings.huggingface) (1.9.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in c:\\python312\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (0.4.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\python312\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (2.29.0)\n",
      "Requirement already satisfied: google-api-core in c:\\python312\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (2.19.0)\n",
      "Requirement already satisfied: protobuf in c:\\python312\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (1.23.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.20.0->beyondllm) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.20.0->beyondllm) (0.14.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.19 in c:\\python312\\lib\\site-packages (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.27->beyondllm) (0.1.19)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\python312\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27->beyondllm) (4.12.3)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\python312\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27->beyondllm) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in c:\\python312\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.27->beyondllm) (0.4.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.0.3->beyondllm) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (1.12.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm->nltk==3.8.1->beyondllm) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python312\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python312\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27->beyondllm) (3.21.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (3.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27->beyondllm) (2.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\python312\\lib\\site-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (1.63.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (4.9)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index.embeddings.huggingface) (1.3.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (1.63.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (1.62.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->llama-index-embeddings-gemini==0.1.6->beyondllm) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install beyondllm youtube_transcript_api llama-index-readers-youtube-transcript llama_index.embeddings.huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Security Considerations:\n",
    "\n",
    "Avoid Hard-Coding: API keys are sensitive pieces of information. By using getpass, the keys are input securely without being displayed on the screen or stored in the code, protecting them from accidental exposure.\n",
    "### 2- Environment Variables:\n",
    "\n",
    "Why Environment Variables?: Environment variables are used to manage configuration settings and sensitive information like API keys. This approach ensures that these keys are not directly embedded in the codebase, making the application more secure and easier to configure across different environments.\n",
    "### 3- User Prompt:\n",
    "\n",
    "User Interaction: The use of getpass to prompt the user for API keys is a simple and effective way to handle sensitive information. It prevents the keys from being displayed in plaintext, enhancing security during the input process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code: Retrieve API keys and set environment variables\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Securely retrieve and set Hugging Face and Google API keys\n",
    "hf_token = getpass('Enter Your HuggingfaceHub Token')\n",
    "google_api_key = getpass('Enter Your Google API Key')\n",
    "\n",
    "# Set as environment variables\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "os.environ['GOOGLE_API_KEY'] = google_api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Loading**:\n",
    "   - This step initiates the data extraction process from a YouTube video using BeyondLLM's `source.fit` method.\n",
    "   - The video content is divided into chunks of 1024 characters, making it easier to process and analyze.\n",
    "\n",
    "2. **Parameter Explanation**:\n",
    "   - **path**: The URL of the video from which the content will be extracted.\n",
    "   - **dtype**: The type of data source, in this case, \"youtube\", indicates that the input is a YouTube video.\n",
    "   - **chunk_size**: Controls how much text is included in each chunk. Larger chunks might include more context but are also more computationally intensive.\n",
    "   - **chunk_overlap**: Overlap between chunks is set to 0, meaning each chunk is unique and non-repetitive, which is useful for independent processing of sections.\n",
    "\n",
    "The processed data will then be used for embedding, retrieval, and further analysis in subsequent steps of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=ZM1bdh2mDJQ']\n"
     ]
    }
   ],
   "source": [
    "from beyondllm import source, embeddings, retrieve, llms, generator\n",
    "\n",
    "# Load data from a YouTube video\n",
    "data = source.fit(\n",
    "    path=\"https://www.youtube.com/watch?v=ZM1bdh2mDJQ\",  # Video link\n",
    "    dtype=\"youtube\",  # Type of data source\n",
    "    chunk_size=1024,  # Size of data chunks\n",
    "    chunk_overlap=0   # Overlap between chunks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select the embedding model to convert the data into vectors\n",
    "- Embeddings are a crucial step in the pipeline, transforming textual data into numerical vectors that can be processed by machine learning models.\n",
    "- In this case, we are using a pre-trained embedding model from Hugging Face's model repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the embedding model to convert the data into vectors\n",
    "model_name = 'BAAI/bge-small-en-v1.5'  # A model available on Hugging Face\n",
    "embed_model = embeddings.HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configure the advanced retriever\n",
    "- The retriever is a critical component of the RAG pipeline, responsible for fetching the most relevant data chunks in response to a query.\n",
    "- Here, an advanced retriever method is configured to ensure high accuracy and relevance in the retrieval process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the advanced retriever\n",
    "retriever = retrieve.auto_retriever(\n",
    "    data=data,\n",
    "    embed_model=embed_model,\n",
    "    type=\"cross-rerank\",  # Advanced retriever type\n",
    "    mode=\"OR\",            # Operates in 'OR' mode\n",
    "    top_k=2               # Retrieve the top two matches\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Retrieve data with a sample query and display the results\n",
    "-  This section demonstrates how to use the configured retriever to fetch relevant data based on a specific query.\n",
    "-  The retrieved data is then displayed, showing how the RAG pipeline responds to user queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved from the query: [NodeWithScore(node=TextNode(id_='67d5d4af-a155-4bc8-ac77-a18084b72473', embedding=None, metadata={'video_id': 'ZM1bdh2mDJQ'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ZM1bdh2mDJQ', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'video_id': 'ZM1bdh2mDJQ'}, hash='615e7d33180855d5371f6b37c8848fe6cb5ae545e1ba29af48aae860c75a6437')}, text=\"hi everyone welcome to the part seven\\nvideo of building llm applications using\\ngen stack in this video we are going to\\nbuild a CSV agent using this tack so the\\nCSV file will be the data source for the\\nentire R pipeline so if you do not know\\nwhat rag is then in short it's retrieval\\naugmented generation it streamlines the\\nprocess of retrieving data from a data\\nsource then pre-processing it and\\nstoring it in a certain way in a vector\\nstore and then retri it when a query is\\npassed and then presenting it with the\\nhelp of a llm which we're going to\\nprovide and the llm will generate\\nresponse based on the query which is\\nbeing\\nasked so let's start building the rack\\npipeline first of all we need a loader\\nwhich in this case will be a CSV loader\\nsince we are using a CSV file so let's\\ndrag and drop uh now I'll be using a\\nTitanic data set which I have downloaded\\nfrom kaggle so yeah I'll be using that\\ndata ass it as the reference data source\\nof this\\npipeline so I've uploaded the data now\\nwe need to split the text into smaller\\nchunks so that it could fit into the llm\\nthat we're going to use in the future so\\nyeah let's do that right now uh here\\nI'll be using the recursive character\\ntext splitter and I'll be joining both\\nof the components so now since we have\\nour smaller chunks of text we can uh\\nconvert it to uh numerical embeddings\\nwith the help of an embedding model so\\nuh let's do that uh we need a hugging\\nface inference API embeddings and I'll\\nput my API key and also the model name\\nso I've added the API key and the model\\nname here I'll be using this model\\nmentioned in the model name now since we\\nhave our embedding model defined we also\\nneed to convert those text information\\ninto embeddings and then we have to\\nstore it in a separate Vector store here\\nI'm going to use the chroma Vector store\\nand I'll be connecting\\nthis both\\ncomponents like this so as you can see\\nuh these all are the retriever\\ncomponents so whenever we ask a query to\\nthe rack pipeline the vector store\\nfetches the most relevant information\\nand passes it to the generator component\\nwhich generates a proper answer and\\ngives to us so let's start building the\\ngenerator component for that we need an\\nllm here I'll be using the Azure chat\\nopeni so you have to put the Azure chat\\nopeni API base the API key\\nthe type and the deployment name along\\nwith the model name so I'll fill all the\\nfields and unfortunately I cannot expose\\nthem in the video now since we have\\ndefined our llm we need to connect the\\ngenerator component with the Ral\\ncomponent which you can see on your\\nscreen so for that we need chains first\\nof all I will drag and drop the combine\\ndocs chain and after that uh I need to\\nhave the retrieval qm I will connect\\nboth of the components and I will\\nconnect the chroma to the Reet component\\nso this is how we have our generator\\ncomponent ready but before that we have\\nto connect the llm to the combine do\\nstream so I'll do that right now after\\nconnecting all the components we can\\nbuild the entire rack pipeline by\\nclicking on this buildt stack\\nbutton once the stack is built you can\\nchat with your application by clicking\\non the chat with stack button which is\\npresent just below the build stack\\nbutton it will notify you once the stack\\nis ready for\\ntesting so as you can see our stack is\\nready for testing and we are going to\\nchat with our application so let's ask\\nwhat are some of the values of the field\\nP class the field P class is present in\\nthe CSV file which I have uploaded for\\nreference so it answers in the G given\\ncontext the values of class are 1 and\\nthree so it automatically recognizes\\nthat the value class refers to P class\\nso yeah as you can see building this\\nentire application took me just a few\\nminutes so you can also build your\\napplication by using a separate CSV file\\nlet's say or we also have supports for\\nPDF and other types of data so you can\\nalso experiment with the embedding model\\nand the llm so yeah you can also try\\nbuilding your own stack I hope this\\nvideo was helpful if you like this video\\nplease let us know by hitting on the\\nlike button and subscribing to the\\nchannel we will release more videos in\\nthis series to solve new use cases till\\nthen stay tuned thank you\", mimetype='text/plain', start_char_idx=0, end_char_idx=4190, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=-5.187207)]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve data with a sample query and display the results\n",
    "query = \"Which tool is mentioned in the video?\"\n",
    "retrieved_nodes = retriever.retrieve(query)\n",
    "print(\"Data retrieved from the query:\", retrieved_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Configure a language model from Hugging Face\n",
    "-  This step involves setting up a Large Language Model (LLM) that will be used to generate responses based on the data retrieved from the RAG pipeline.\n",
    "-  The model selected is hosted on Hugging Face's model hub, and requires an API token for access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a language model from Hugging Face\n",
    "llm = llms.HuggingFaceHubModel(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",  # An LLM from Hugging Face\n",
    "    token=os.environ.get('HF_TOKEN')            # Using the Hugging Face API token\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding system prompt\n",
    "system_prompt = f\"\"\"\n",
    "<s>[INST]\n",
    "You are an AI Assistant.\n",
    "Please provide direct answers to questions.\n",
    "[/INST]\n",
    "</s>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Create a query and get a response from the pipeline\n",
    "-  This step ties together all the components of the RAG pipeline, where a user query is processed, relevant data is retrieved, and a response is generated.\n",
    "-  The response is produced by the language model, guided by a system prompt that ensures the generated text is relevant and coherent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query and get a response from the pipeline\n",
    "pipeline = generator.Generate(\n",
    "    question=query,            # Using the \"query\" variable as the question\n",
    "    retriever=retriever,\n",
    "    system_prompt=system_prompt,  # Adding the system prompt\n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response: \n",
      "        ANSWER: The tools mentioned in the video are Titanic dataset (for reference data), Turing Tame Machine (TTM) for text splitting, Hugging Face Inference API for embedding model, Chroma Vector Store, Azure Chat Openi for LLM, and Rack for building the pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Get the response and display it\n",
    "response = pipeline.call()\n",
    "print(\"Model response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing RAG Triad Evaluations...\n",
      "RAG Triad Evaluation: Context relevancy Score: 10.0\n",
      "This response meets the evaluation threshold. It demonstrates strong comprehension and coherence.\n",
      "Answer relevancy Score: 10.0\n",
      "This response meets the evaluation threshold. It demonstrates strong comprehension and coherence.\n",
      "Groundness score: 7.0\n",
      "This response does not meet the evaluation threshold. Consider refining the structure and content for better clarity and effectiveness.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and display RAG Triad evaluation metrics\n",
    "rag_evals = pipeline.get_rag_triad_evals()\n",
    "print(\"RAG Triad Evaluation:\", rag_evals)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
